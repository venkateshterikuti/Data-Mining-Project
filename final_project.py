# -*- coding: utf-8 -*-
"""Final project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16pwBfHd5Gs8N3-L6_R-pkBZ1y-HzaU4H
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LogisticRegression

from scipy import stats
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('Cancer_Data.csv')  #Readind the Cancer dataset

print(df)

num_rows = df.shape[0]
num_cols = df.shape[1]
print("Number of rows:", num_rows)
print("Number of columns:", num_cols)

df.head()

df.isna().sum()

df.drop(['id', 'Unnamed: 32'], axis = 1, inplace = True)  #Dropping the ID and Unnamed: 32 coloumns

df.info()

df.describe()

df.head()

df['diagnosis'] = df['diagnosis'].map({'B' : 0, 'M' : 1})

df.head()

corr_table = df.corr(method='pearson')
corr_table

corr_matrix = df.corr(method='pearson')

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')

plt.show()

df.drop(['smoothness_mean', 'symmetry_mean','fractal_dimension_mean','texture_se','smoothness_se','compactness_se','concavity_se','symmetry_se','fractal_dimension_worst','fractal_dimension_se'], axis = 1, inplace = True)

df.info()

df['radius_mean'] = (df['radius_mean'] - df['radius_mean'].min()) / (df['radius_mean'].max() - df['radius_mean'].min())
df['texture_mean'] = (df['texture_mean'] - df['texture_mean'].min()) / (df['texture_mean'].max() - df['texture_mean'].min())
df['perimeter_mean'] = (df['perimeter_mean'] - df['perimeter_mean'].min()) / (df['perimeter_mean'].max() - df['perimeter_mean'].min())
df['area_mean'] = (df['area_mean'] - df['area_mean'].min()) / (df['area_mean'].max() - df['area_mean'].min())
df['compactness_mean'] = (df['compactness_mean'] - df['compactness_mean'].min()) / (df['compactness_mean'].max() - df['compactness_mean'].min())
df['concavity_mean'] = (df['concavity_mean'] - df['concavity_mean'].min()) / (df['concavity_mean'].max() - df['concavity_mean'].min())
df['concave points_mean'] = (df['concave points_mean'] - df['concave points_mean'].min()) / (df['concave points_mean'].max() - df['concave points_mean'].min())
df['radius_se'] = (df['radius_se'] - df['radius_se'].min()) / (df['radius_se'].max() - df['radius_se'].min())
df['perimeter_se'] = (df['perimeter_se'] - df['perimeter_se'].min()) / (df['perimeter_se'].max() - df['perimeter_se'].min())
df['area_se'] = (df['area_se'] - df['area_se'].min()) / (df['area_se'].max() - df['area_se'].min())
df['concave points_se'] = (df['concave points_se'] - df['concave points_se'].min()) / (df['concave points_se'].max() - df['concave points_se'].min())
df['radius_worst'] = (df['radius_worst'] - df['radius_worst'].min()) / (df['radius_worst'].max() - df['radius_worst'].min())
df['texture_worst'] = (df['texture_worst'] - df['texture_worst'].min()) / (df['texture_worst'].max() - df['texture_worst'].min())
df['perimeter_worst'] = (df['perimeter_worst'] - df['perimeter_worst'].min()) / (df['perimeter_worst'].max() - df['perimeter_worst'].min())
df['area_worst'] = (df['area_worst'] - df['area_worst'].min()) / (df['area_worst'].max() - df['area_worst'].min())
df['smoothness_worst'] = (df['smoothness_worst'] - df['smoothness_worst'].min()) / (df['smoothness_worst'].max() - df['smoothness_worst'].min())
df['compactness_worst'] = (df['compactness_worst'] - df['compactness_worst'].min()) / (df['compactness_worst'].max() - df['compactness_worst'].min())
df['concavity_worst'] = (df['concavity_worst'] - df['concavity_worst'].min()) / (df['concavity_worst'].max() - df['concavity_worst'].min())
df['concave points_worst'] = (df['concave points_worst'] - df['concave points_worst'].min()) / (df['concave points_worst'].max() - df['concave points_worst'].min())
df['symmetry_worst'] = (df['symmetry_worst'] - df['symmetry_worst'].min()) / (df['symmetry_worst'].max() - df['symmetry_worst'].min())

print(df.head())

X = df.drop('diagnosis', axis = 1)
y = df['diagnosis']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

classifier = svm.SVC(kernel='linear', C=1)

classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
print("F1:",f1)
print("Recall",recall)
print("Precision:",precision)
print("Accuracy:", accuracy)


# Split the data for logistic regression
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Scale the features before training the model
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Make predictions on test set
y_pred = log_reg.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
print("F1:", f1)
print("Recall", recall)
print("Precision:", precision)
print("Accuracy:", accuracy)

from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline

# Evaluate models using pipelines and cross-validation
log_reg_pipe = make_pipeline(StandardScaler(), LogisticRegression())
svm_pipe = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1))

log_scores = cross_val_score(log_reg_pipe, X, y, cv=5, scoring='accuracy')
svm_scores = cross_val_score(svm_pipe, X, y, cv=5, scoring='accuracy')

print(
    "Cross-validation accuracy (Logistic Regression): {:.2f} ± {:.2f}".format(
        np.mean(log_scores), np.std(log_scores)
    )
)
print(
    "Cross-validation accuracy for SVM: {:.2f} ± {:.2f}".format(
        np.mean(svm_scores), np.std(svm_scores)
    )
)

